{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharvas/dirp_neurosymbolic/blob/master/Week1_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NLSJ8QRZE6Pk",
        "outputId": "436103ef-d0c6-4d36-f9c1-2f1b086cc139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_ONxujUVUHd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c1192d-053e-422a-8cf3-db33bba2a9f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "/content/dirp_neurosymbolic\n",
            "Archive:  data/raw/VizDrone2019/VisDrone2019-MOT-train.zip\n",
            "caution: filename not matched:  data/raw/VizDrone2019/VisDrone2019-SOT-test-dev.zip\n",
            "caution: filename not matched:  data/raw/VizDrone2019/VisDrone2019-SOT-train_part2.zip\n",
            "caution: filename not matched:  data/raw/VizDrone2019/VisDrone2019-SOT-val.zip\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import shutil\n",
        "# !git clone https://github.com/atharvas/dirp_neurosymbolic.git\n",
        "%cd /content/dirp_neurosymbolic/\n",
        "# Workaround for running git.\n",
        "# Make a personal access token and put it into ./token.txt\n",
        "# https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token\n",
        "!touch token.txt\n",
        "# Store the personal access token @ stache.utexas.edu!\n",
        "\n",
        "shutil.copytree(\"/content/drive/MyDrive/VizDrone2019\", \"data/raw/VizDrone2019\", )\n",
        "!unzip data/raw/VizDrone2019/*.zip -d data/raw/VizDrone2019/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from highwaydetector import utils\n",
        "\n",
        "!git config --global user.email \"atharva.sehgal@gmail.com\"\n",
        "!git config --global user.name \"Atharva Sehgal\"\n",
        "username = \"atharvas\"\n",
        "token = utils.read_txt(\"token.txt\")[0]\n",
        "!git remote set-url origin https://{username}:{token}@github.com/atharvas/dirp_neurosymbolic.git\n"
      ],
      "metadata": {
        "id": "RWIOMS_Z5XKV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from highwaydetector.dataset import download_dataset\n",
        "\n",
        "!mkdir -p data/raw/\n",
        "!mkdir -p data/processed/train\n",
        "!mkdir -p data/processed/test\n",
        "# download_dataset(\"https://www.jpjodoin.com/urbantracker/dataset/rene/rene_frames.zip\")\n",
        "!wget https://www.jpjodoin.com/urbantracker/dataset/rene/rene_frames.zip -O data/raw/rene_frames.zip\n",
        "!wget https://atharvas.github.io/static/notmyarchive.zip -O data/raw/notmyarchive.zip\n",
        "\n",
        "!unzip data/raw/rene_frames.zip -d data/processed/test/\n",
        "!unzip data/raw/notmyarchive.zip -d data/raw/\n"
      ],
      "metadata": {
        "id": "6CxQeNaEVGO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# video_info = pd.read_csv(\"/content/dirp_neurosymbolic/data/raw/info.txt\", sep=\"\\t\", skiprows=[0], header=None)\n",
        "def extract_frames_from_videos(video_dir = 'data/raw/video', output_dir = 'data/processed/train/') -> None:\n",
        "    for video in os.listdir(video_dir):\n",
        "        video_name, ext = os.path.splitext(video)\n",
        "        video_path = os.path.join(video_dir, video)\n",
        "        png_path   = os.path.join(output_dir, video_name, \"%06d.png\")\n",
        "        # num_frames = video_info[video_info[0] == video_name][7].item()\n",
        "        os.makedirs(os.path.dirname(png_path), exist_ok=True)\n",
        "        utils.exec_cmd(f\"ffmpeg -i {video_path} '{png_path}' &> /dev/null \")\n",
        "\n",
        "extract_frames_from_videos()"
      ],
      "metadata": {
        "id": "44t_ODaHZtvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from highwaydetector.dataset import VideoLoader\n",
        "import torchvision.transforms as tf\n",
        "\n",
        "\n",
        "dataset = VideoLoader(\"data/processed/train\", max_seq_len=2, image_size=(128, 128))\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "for sample in dataloader:\n",
        "    print(sample.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "mNWXOv-fEUxJ",
        "outputId": "aa9e1475-7048-48c2-ad62-fd98a289058f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 131, 3, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://modelzoo.co/\n",
        "# \n"
      ],
      "metadata": {
        "id": "7e4FidqvEda6",
        "outputId": "f8c0a5fb-2a32-427b-8a9a-d505b2fd902f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "Your branch is up to date with 'origin/master'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
            "\n",
            "\t\u001b[31mmodified:   highwaydetector/__pycache__/dataset.cpython-37.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   highwaydetector/__pycache__/utils.cpython-37.pyc\u001b[m\n",
            "\t\u001b[31mmodified:   highwaydetector/dataset.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31mdata/\u001b[m\n",
            "\t\u001b[31mtoken.txt\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
            "[master d225c3e] added dataset\n",
            " 1 file changed, 23 insertions(+), 6 deletions(-)\n",
            "Counting objects: 4, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 760 bytes | 760.00 KiB/s, done.\n",
            "Total 4 (delta 3), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n",
            "To https://github.com/atharvas/dirp_neurosymbolic.git\n",
            "   04d5acf..d225c3e  master -> master\n"
          ]
        }
      ]
    }
  ]
}